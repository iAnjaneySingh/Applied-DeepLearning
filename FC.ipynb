{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpSnhz6KwAR2"
      },
      "source": [
        "Keras is a powerful and easy-to-use Python library for developing and evaluating deep learning models. It wraps the efficient numerical computation libraries Theano, CNTK and TensorFlow and allows you to define and train neural network models in a few short lines of code. In this tutorial you will discover how to create your first neural network model in Python using Keras. After completing this lesson you will know:\n",
        "\n",
        "\n",
        "*   How to load a dataset for use with Keras.\n",
        "*   How to define and compile a Multilayer Perceptron model in Keras.\n",
        "*   How to evaluate a Keras model on a validation dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6sPb6S9wTew"
      },
      "source": [
        "# Load Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZw7VarZwd-G"
      },
      "source": [
        "First step is to load the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWwF5yAuw2Xx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "88e303db-b51b-4a1c-c0b8-3a944e9c8ed2"
      },
      "source": [
        "import numpy \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578Oi4Mgw9hr"
      },
      "source": [
        "# Load Dataset in Numpy Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxW0gFlxxAK9"
      },
      "source": [
        "MNIST is a simple computer vision dataset. It consists of images of handwritten digits. It also includes labels for each image, telling us which digit it is.\n",
        "\n",
        "The MNIST data is split into three parts: $60,000$ data points of training data, and $10,000$ points of test data. Each image is 28 pixels by 28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9nKAP49x0GI"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4JngwOmyDpP"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NParITruySsa"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9qDBv-5yY3o"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT_EfqFVydlx"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZllUnvJyiQ7"
      },
      "source": [
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C1TncQhzapf"
      },
      "source": [
        "# Formatting Data and Labels for Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuUHfffMzcnG"
      },
      "source": [
        "We can flatten this array into a vector of $28\\times28 = 784$ numbers. It doesn't matter how we flatten the array, as long as we're consistent between images. From this perspective, the MNIST images are just a bunch of points in a 784-dimensional vector space. The data should always be of the format (Number of data points, data point dimension). In this case the training data will be of format $60,000\\times784$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUAPRSm5zj0q"
      },
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "X_train = X_train / 255\n",
        "\n",
        "X_test = X_test / 255\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qa_Wz5Bzu_x"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKMkULioz0BC"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjXdMAgQz3Yk"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwG7OnE5z5av"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUZqC-Mf0F4a"
      },
      "source": [
        "# Defining a single layer neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5-Tn0K30Hyq"
      },
      "source": [
        "Here we will define a single layer neural network. It will have a input layer of $784$ neurons, i.e. the input dimension and output layer of $10$ neurons, i.e. number of classes. The activation function used will be softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlB928RI0LWk"
      },
      "source": [
        "# create model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(num_classes, input_dim=num_pixels, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0woBCP1C0TV-"
      },
      "source": [
        "# Compiling the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aSmUA3-0WIJ"
      },
      "source": [
        "Once the model is defined, we have to compile it. While compiling we provide the loss function to be used, the optimizer and any metric. Here we will use crossentropy loss with Adam optimizer and accuracy as a metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8n--FDX0YjB"
      },
      "source": [
        "# Compile model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq5f_ROP0ieD"
      },
      "source": [
        "# Training/Fitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3gWi2g40kSf"
      },
      "source": [
        "Now the model is ready to be trained. We will provide training data to the network. Also we will specify the validation data, over which the model will only be validated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsJq43ok0mlT"
      },
      "source": [
        "# Training model\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BjzfDW0w6v"
      },
      "source": [
        "# Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0FdSOdT01df"
      },
      "source": [
        "Finally we will evaluate the model on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atp-I5qg04Ao"
      },
      "source": [
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ux0ZGYe1Abb"
      },
      "source": [
        "# Defining a multi-layer model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9zn7vqG1DUh"
      },
      "source": [
        "Now we will define a multi layer neural network in which we will add $2$ hidden layers having $500$ and $100$ neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyWnrEko1D-4"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(500, input_dim=num_pixels, activation='relu'))\n",
        "\n",
        "model.add(Dense(100, activation='relu'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OT0zQrT1FtF"
      },
      "source": [
        "# Compile model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXWqw37F1QC1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}